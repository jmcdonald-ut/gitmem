import { z } from "zod"
import { zodOutputFormat } from "@anthropic-ai/sdk/helpers/zod"
import type { CommitInfo, EvalVerdict } from "@/types"
import { CLASSIFICATIONS } from "@/types"

const VerdictSchema = z.object({
  pass: z.boolean(),
  reasoning: z.string(),
  suggestedClassification: z.enum(CLASSIFICATIONS).optional(),
})

export const EvalResponseSchema = z.object({
  classification: VerdictSchema,
  accuracy: VerdictSchema,
  completeness: VerdictSchema,
})

export const EVAL_OUTPUT_CONFIG = {
  format: zodOutputFormat(EvalResponseSchema),
}

/** System prompt used for all judge evaluation requests. */
export const JUDGE_SYSTEM_PROMPT = `You are a quality evaluator for git commit classifications and summaries. You will be given a commit message, diff, file list, and the classification and summary that were generated by another model. Your job is to evaluate the quality of that classification and summary.

Evaluate three dimensions:
1. Classification correctness — Is the assigned category the best fit for this commit?
2. Summary accuracy — Does the summary accurately describe what actually changed?
3. Summary completeness — Does the summary capture the most important changes?

Valid classifications: ${CLASSIFICATIONS.join(", ")}

Classification guidelines (use these to judge correctness):
- bug-fix: fixes a defect, corrects broken behavior, or restores intended functionality
- feature: adds new user-facing functionality or capabilities that did not exist before
- refactor: restructures existing code without changing external behavior (internal improvements only)
- docs: changes to documentation content meant for humans to read (README, guides, tutorials, API docs)
- chore: maintenance tasks — dependency updates, CI config, version bumps, merge commits, build tooling, changelogs, release notes, repo infrastructure (.github/*, PR templates, issue templates, .editorconfig)
- perf: changes that improve efficiency or reduce resource usage, even small ones like moving work outside a loop
- test: adds or modifies test files without changing production code
- style: purely cosmetic changes — formatting, whitespace, semicolons, naming conventions, linting fixes. Must have zero semantic or behavioral effect.

Classification edge cases:
- Merge commits (message starts with "Merge") should be classified as "chore".
- When a commit spans multiple categories, classify by its primary purpose.
- Improving existing behavior or internal implementation without adding new user-facing capability is "refactor", not "feature".
- Changing existing error messages, validation messages, or user-facing text wording is "style", not "feature". Only "feature" if entirely new message types or validation rules are added.
- CHANGELOG and release note updates are "chore", not "docs".
- Adding or configuring dev tooling (linters, git hooks, formatters, CI pipelines) is "chore", not "feature".
- Moving code for efficiency (e.g. hoisting an assignment out of a loop) is "perf", not "style".
- Removing deprecated code or making breaking API changes is "chore", not "refactor". True refactors preserve external behavior.
- Adding locale/translation files for an existing feature is "chore", not "feature". The feature already exists; adding a translation is maintenance.
- Updating existing locale/translation text is "style", not "docs". Locale files are runtime UI strings, not documentation.
- Regenerating test fixtures or snapshots without changing test logic is "chore", not "test".
- Fixing broken links (404s), broken builds, or broken configs is "bug-fix" regardless of which file type contains the fix. However, fixing incorrect content in documentation (wrong variable names in examples, wrong property names, typos) is "docs", not "bug-fix" — the documentation content itself is the deliverable being corrected.
- Classify by the purpose of the change, not the file type. A config file change that fixes a broken doc site is "bug-fix", not "docs" or "chore".
- IMPORTANT: Always trust the diff over the commit message. If the message says "fix" but the diff shows only a refactor, the correct classification is "refactor". Do not override a diff-based classification using commit message wording.
- Scratch files, playgrounds, and example scripts are not test files. Changes to non-test non-production files are "chore", not "test".

Classification evaluation approach:
- Pass if the classification is a reasonable fit for the commit, even if another classification could also apply.
- Only fail if the classification is clearly wrong — i.e., there is a substantially better classification that the original clearly should have been.

Accuracy evaluation guidelines:
- Fail if the summary claims something changed that didn't, describes the wrong component, or misidentifies what type of change was made.
- Fail if the summary speculates about motivation or impact not supported by the diff.
- Do not fail for omissions — that is a completeness issue, not an accuracy issue.
- Pass if the summary correctly describes the change even with different wording or paraphrasing.

Completeness evaluation guidelines:
- Judge whether the summary captures the primary purpose and the most significant changes.
- Fail if a major change or significant portion of the diff is unmentioned.
- If the diff is empty or minimal (e.g. merge commits), do not fail completeness for lack of detail that cannot be inferred from the available information.
- Do not fail for omitting minor or incidental details (e.g. a comment that wasn't updated, trivial formatting).`

/**
 * Builds the user message sent to the judge for evaluation.
 * @param commit - The commit metadata.
 * @param diff - The unified diff content.
 * @param classification - The original enrichment classification.
 * @param summary - The original enrichment summary.
 * @returns The formatted user message string.
 */
export function buildJudgeUserMessage(
  commit: CommitInfo,
  diff: string,
  classification: string,
  summary: string,
): string {
  const fileList = commit.files
    .map(
      (f) => `${f.changeType} ${f.filePath} (+${f.additions} -${f.deletions})`,
    )
    .join("\n  ")

  return `Commit message: ${commit.message}

Files changed:
  ${fileList}

Diff:
${diff}

--- Enrichment to evaluate ---
Classification: ${classification}
Summary: ${summary}`
}

/**
 * Parses the judge JSON response into evaluation verdicts.
 * With structured outputs, the API guarantees valid JSON matching the schema.
 * @param text - Raw text response from the judge.
 * @returns The three evaluation verdicts.
 */
export function parseEvalResponse(text: string): {
  classificationVerdict: EvalVerdict
  accuracyVerdict: EvalVerdict
  completenessVerdict: EvalVerdict
} {
  const parsed = EvalResponseSchema.parse(JSON.parse(text))

  return {
    classificationVerdict: toVerdict(parsed.classification),
    accuracyVerdict: toVerdict(parsed.accuracy),
    completenessVerdict: toVerdict(parsed.completeness),
  }
}

/**
 * Detects and fixes self-contradictory classification verdicts where
 * the judge says pass=false but suggests the same classification that
 * was originally assigned.
 */
export function reconcileClassificationVerdict(
  originalClassification: string,
  verdict: EvalVerdict,
): EvalVerdict {
  if (
    !verdict.pass &&
    verdict.suggestedClassification === originalClassification
  ) {
    return { pass: true, reasoning: verdict.reasoning }
  }
  return verdict
}

function toVerdict(raw: {
  pass: boolean
  reasoning: string
  suggestedClassification?: string
}): EvalVerdict {
  const verdict: EvalVerdict = {
    pass: raw.pass,
    reasoning: raw.reasoning,
  }
  if (raw.suggestedClassification) {
    verdict.suggestedClassification =
      raw.suggestedClassification as EvalVerdict["suggestedClassification"]
  }
  return verdict
}
